package com.clauder.agent

import com.claude.agent.common.database.normalizeToRange
import kotlinx.coroutines.runBlocking
import java.io.File

val documentReader = DocumentReader()
val dataBase = DataBase()

/**
 * Main entry point for RAG index building
 *
 * Usage:
 *   ./gradlew :rag:run --args="<docs_directory> [db_path] [ollama_url]"
 *
 * Example:
 *   ./gradlew :rag:run --args="./docs"
 *   ./gradlew :rag:run --args="./docs rag_index.db http://localhost:11434"
 */
fun main(args: Array<String>) = runBlocking {
    println("ğŸš€ RAG Index Builder")
    println("=" .repeat(50))

    // Parse arguments
    val docsDir = if (args.isNotEmpty()) {
        File(args[0])
    } else {
        println("âŒ Error: Please provide documents directory path")
        println("Usage: ./gradlew :rag:run --args=\"<docs_directory> [db_path] [ollama_url]\"")
        return@runBlocking
    }

    if (!docsDir.exists() || !docsDir.isDirectory) {
        println("âŒ Error: Directory not found: ${docsDir.absolutePath}")
        return@runBlocking
    }

    val dbPath = if (args.size > 1) args[1] else "rag_index.db"
    val ollamaUrl = if (args.size > 2) args[2] else "http://localhost:11434"

    println("ğŸ“‚ Documents directory: ${docsDir.absolutePath}")
    println("ğŸ’¾ Database path: $dbPath")
    println("ğŸ¤– Ollama URL: $ollamaUrl")
    println()

    // Initialize database with Exposed
    dataBase.initDatabase(dbPath)
    dataBase.initSchema()

    // Initialize Ollama client
    val ollama = OllamaClient(ollamaUrl)

    try {
        // Build index
        buildIndex(docsDir, ollama)

        // Print statistics
        val totalChunks = dataBase.getChunkCount()
        println()
        println("=" .repeat(50))
        println("âœ… Index built successfully!")
        println("ğŸ“Š Total chunks indexed: $totalChunks")
        println("ğŸ’¾ Database: $dbPath")

    } catch (e: Exception) {
        println("âŒ Error building index: ${e.message}")
        e.printStackTrace()
    } finally {
        ollama.close()
    }
}

/**
 * Build index from documents directory
 */
suspend fun buildIndex(
    docsDir: File,
    ollama: OllamaClient
) {
    val docs = documentReader.loadDocuments(docsDir)

    if (docs.isEmpty()) {
        println("âš ï¸  No documents found in ${docsDir.absolutePath}")
        return
    }

    println("ğŸ“š Found ${docs.size} documents")
    println()

    for ((index, docPair) in docs.withIndex()) {
        val (docId, text) = docPair
        println("ğŸ“„ [${index + 1}/${docs.size}] Processing: $docId")
        println("   ğŸ“ Text length: ${text.length} characters")

        // Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ½Ğ° Ñ‡Ğ°Ğ½ĞºĞ¸
        val chunks = chunkText(docId, text)
        println("   âœ‚ï¸  Created ${chunks.size} chunks")

        // ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‡Ğ°Ğ½ĞºĞ¸ Ğ±Ğ°Ñ‚Ñ‡Ğ°Ğ¼Ğ¸ Ğ´Ğ»Ñ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
        val batchSize = 10
        var processedChunks = 0

        for (batchStart in chunks.indices step batchSize) {
            val batchEnd = minOf(batchStart + batchSize, chunks.size)
            val batch = chunks.subList(batchStart, batchEnd)

            for (chunk in batch) {
                print("   ğŸ”¹ Chunk ${chunk.index + 1}/${chunks.size} - Generating embedding...")

                val embedding = ollama.embed(chunk.text)
                val normalized = normalizeToRange(embedding)

                dataBase.insertEmbedding(
                    docId = chunk.docId,
                    chunkIndex = chunk.index,
                    text = chunk.text,
                    vector = normalized
                )

                processedChunks++
                println(" âœ“ (${processedChunks}/${chunks.size})")
            }

            // ĞŸĞ¾Ğ´ÑĞºĞ°Ğ·ĞºĞ° GC Ğ¾ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Ğ¿Ğ¾ÑĞ»Ğµ Ğ±Ğ°Ñ‚Ñ‡Ğ°
            System.gc()
        }

        println("   âœ… Document processed: ${processedChunks} chunks")
        println()
    }

    println("ğŸ‰ Index building complete!")
    println("ğŸ“Š Total chunks: ${dataBase.getChunkCount()}")
}